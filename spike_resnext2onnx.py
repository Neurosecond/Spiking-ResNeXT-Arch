import torch
import torch.nn as nn
import torch.nn.functional as F
import snntorch as snn
from torch.utils.data import Dataset, DataLoader
import numpy as np
import pandas as pd
import os

import onnx
import onnxruntime as ort

# =============================================================================
# 2. –ö–û–î–ò–†–û–í–©–ò–ö –î–ê–ù–ù–´–• –í –°–ü–ê–ô–ö–ò
# =============================================================================

class FinancialSpikeEncoder:
    """–ö–æ–¥–∏—Ä–æ–≤—â–∏–∫ —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å–ø–∞–π–∫–∏"""

    def __init__(self, num_time_steps=50, threshold_std=1.0):
        self.num_time_steps = num_time_steps
        self.threshold_std = threshold_std

    def price_change_encoding(self, price_data):
        """–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏–π —Ü–µ–Ω—ã –≤ —Å–ø–∞–π–∫–∏"""
        # price_data shape: (batch_size, seq_len, num_features)
        batch_size, seq_len, num_features = price_data.shape

        # –í—ã—á–∏—Å–ª—è–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ü–µ–Ω—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
        price_changes = np.diff(price_data, axis=1)  # (batch_size, seq_len-1, num_features)

        # –°–æ–∑–¥–∞–µ–º —Å–ø–∞–π–∫–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
        spike_tensor = np.zeros((batch_size, 3, seq_len, self.num_time_steps))

        for batch_idx in range(batch_size):
            for feature_idx in range(num_features):
                feature_changes = price_changes[batch_idx, :, feature_idx]

                if len(feature_changes) == 0:
                    continue

                # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–∏–∑–Ω–∞–∫–∞
                mean_change = np.mean(feature_changes)
                std_change = np.std(feature_changes)

                if std_change < 1e-8:
                    normalized_changes = np.zeros_like(feature_changes)
                else:
                    normalized_changes = (feature_changes - mean_change) / std_change

                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ø–∞–π–∫–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ—Ä–æ–≥–æ–≤
                for step_idx, change in enumerate(normalized_changes):
                    if step_idx >= seq_len - 1:  # –ó–∞—â–∏—Ç–∞ –æ—Ç –≤—ã—Ö–æ–¥–∞ –∑–∞ –≥—Ä–∞–Ω–∏—Ü—ã
                        continue

                    if change > self.threshold_std:
                        # –°–ø–∞–π–∫ –≤–≤–µ—Ä—Ö
                        spike_indices = np.linspace(0, self.num_time_steps - 1, 3, dtype=int)
                        spike_tensor[batch_idx, 0, step_idx, spike_indices] = 1
                    elif change < -self.threshold_std:
                        # –°–ø–∞–π–∫ –≤–Ω–∏–∑
                        spike_indices = np.linspace(0, self.num_time_steps - 1, 3, dtype=int)
                        spike_tensor[batch_idx, 1, step_idx, spike_indices] = 1
                    else:
                        # –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
                        spike_indices = np.random.choice(self.num_time_steps, 1)
                        spike_tensor[batch_idx, 2, step_idx, spike_indices] = 1

        return torch.FloatTensor(spike_tensor)


# =============================================================================
# 3. –ê–†–•–ò–¢–ï–ö–¢–£–†–ê –°–ü–ê–ô–ö–û–í–û–ô RESNEXT (–ë–ï–ó –°–û–•–†–ê–ù–ï–ù–ò–Ø –°–û–°–¢–û–Ø–ù–ò–Ø)
# =============================================================================

class MultiTimeframeSpikingResNeXt(nn.Module):
    """–°–ø–∞–π–∫–æ–≤–∞—è ResNeXt –¥–ª—è –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ EURUSD"""

    def __init__(self, num_timeframes=4, num_classes=3, num_steps=50,
                 cardinality=16, beta=0.9):
        super().__init__()

        self.num_steps = num_steps
        self.num_timeframes = num_timeframes

        # –û–î–ù–ê –æ–±—â–∞—è –≤—Ö–æ–¥–Ω–∞—è —Å–≤–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)
        self.bn1 = nn.BatchNorm2d(64)
        self.lif1 = snn.Leaky(beta=beta, learn_beta=True)
        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)

        # ResNeXt –±–ª–æ–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ features
        self.resnext_blocks = nn.Sequential(
            SparseSpikingResNeXtBlock(64, 128, stride=2, cardinality=cardinality),
            SparseSpikingResNeXtBlock(128, 256, stride=2, cardinality=cardinality),
            SparseSpikingResNeXtBlock(256, 512, stride=1, cardinality=cardinality),
        )

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.classifier = nn.Sequential(
            nn.Linear(512 * num_timeframes, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        # x shape: (batch, num_timeframes, 3, height, width, num_steps)
        batch_size = x.shape[0]
        num_tf = x.shape[1]
        height = x.shape[3]
        width = x.shape[4]
        num_steps = x.shape[5]

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–µ–º–±—Ä–∞–Ω–Ω—ã—Ö –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–æ–≤ (–í–†–ï–ú–ï–ù–ù–´–ï –¥–ª—è —ç—Ç–æ–≥–æ –≤—ã–∑–æ–≤–∞)
        mem1 = self.lif1.init_leaky()

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —à–∞–≥
        timeframe_features = []

        for tf_idx in range(num_tf):
            tf_step_features = []

            for step in range(num_steps):
                x_tf_step = x[:, tf_idx, :, :, :, step]  # (batch, 3, height, width)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º –≤—Ö–æ–¥–Ω—É—é —Å–≤–µ—Ä—Ç–∫—É
                x_conv = self.conv1(x_tf_step)
                x_conv = self.bn1(x_conv)
                x_conv, mem1 = self.lif1(x_conv, mem1)  # –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å
                x_conv = self.pool1(x_conv)

                # –ü—Ä–∏–º–µ–Ω—è–µ–º ResNeXt –±–ª–æ–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é
                x_features = self._forward_resnext_blocks(x_conv)

                # Global average pooling –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è feature vector
                x_pooled = F.adaptive_avg_pool2d(x_features, (1, 1))
                x_pooled = x_pooled.view(batch_size, -1)  # (batch, 512)

                tf_step_features.append(x_pooled)

            # –£—Å—Ä–µ–¥–Ω—è–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–º —à–∞–≥–∞–º –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞
            tf_all_steps = torch.stack(tf_step_features, dim=0)  # (num_steps, batch, 512)
            tf_avg = tf_all_steps.mean(dim=0)  # (batch, 512)
            timeframe_features.append(tf_avg)

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º features –æ—Ç –≤—Å–µ—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
        combined_features = torch.cat(timeframe_features, dim=1)  # (batch, num_tf * 512)

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        output = self.classifier(combined_features)

        return output

    def _forward_resnext_blocks(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —á–µ—Ä–µ–∑ ResNeXt –±–ª–æ–∫–∏ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç—å—é"""
        for block in self.resnext_blocks:
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ —Å–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ–º–±—Ä–∞–Ω–Ω—ã–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—ã
            if isinstance(block, SparseSpikingResNeXtBlock):
                x = block.forward_with_temp_mem(x)
            else:
                x = block(x)
        return x

    def reset_mem(self):
        """–¢–µ–ø–µ—Ä—å —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –Ω–µ –Ω—É–∂–Ω–∞, –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        pass


class SparseSpikingResNeXtBlock(nn.Module):
    """–°–ø–∞–π–∫–æ–≤—ã–π –±–ª–æ–∫ ResNeXt —Å –≥—Ä—É–ø–ø–æ–≤—ã–º–∏ —Å–≤–µ—Ä—Ç–∫–∞–º–∏"""

    def __init__(self, in_channels, out_channels, stride=1, cardinality=32,
                 width_factor=4, beta=0.9):
        super().__init__()

        self.beta = beta
        intermediate_channels = cardinality * width_factor

        self.conv1 = nn.Conv2d(in_channels, intermediate_channels,
                               kernel_size=1, bias=False)
        self.bn1 = nn.BatchNorm2d(intermediate_channels)

        self.conv2 = nn.Conv2d(intermediate_channels, intermediate_channels,
                               kernel_size=3, stride=stride, padding=1,
                               groups=cardinality, bias=False)
        self.bn2 = nn.BatchNorm2d(intermediate_channels)

        self.conv3 = nn.Conv2d(intermediate_channels, out_channels,
                               kernel_size=1, bias=False)
        self.bn3 = nn.BatchNorm2d(out_channels)

        self.lif1 = snn.Leaky(beta=beta, learn_beta=True)
        self.lif2 = snn.Leaky(beta=beta, learn_beta=True)
        self.lif3 = snn.Leaky(beta=beta, learn_beta=True)

        self.shortcut = nn.Sequential()
        if stride != 1 or in_channels != out_channels:
            self.shortcut = nn.Sequential(
                nn.Conv2d(in_channels, out_channels, kernel_size=1,
                          stride=stride, bias=False),
                nn.BatchNorm2d(out_channels),
            )
            self.lif_shortcut = snn.Leaky(beta=beta, learn_beta=True)
            self.use_shortcut_lif = True
        else:
            self.use_shortcut_lif = False

        self._initialize_weights()

    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')

    def forward(self, x):
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–º—è—Ç—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        return self.forward_with_temp_mem(x)

    def forward_with_temp_mem(self, x):
        """–ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ–º–±—Ä–∞–Ω–Ω—ã–º–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª–∞–º–∏"""
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø–∞–º—è—Ç–∏
        mem1 = self.lif1.init_leaky()
        mem2 = self.lif2.init_leaky()
        mem3 = self.lif3.init_leaky()

        if self.use_shortcut_lif:
            mem_shortcut = self.lif_shortcut.init_leaky()

        # –û—Å–Ω–æ–≤–Ω–æ–π –ø—É—Ç—å
        out = self.conv1(x)
        out = self.bn1(out)
        out, mem1 = self.lif1(out, mem1)

        out = self.conv2(out)
        out = self.bn2(out)
        out, mem2 = self.lif2(out, mem2)

        out = self.conv3(out)
        out = self.bn3(out)

        # Shortcut –ø—É—Ç—å
        residual = self.shortcut(x)
        if self.use_shortcut_lif:
            residual, mem_shortcut = self.lif_shortcut(residual, mem_shortcut)

        # –°–ª–æ–∂–µ–Ω–∏–µ –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∞–π–∫
        out += residual
        out, mem3 = self.lif3(out, mem3)

        return out

    def reset_mem(self):
        """–¢–µ–ø–µ—Ä—å –Ω–µ –Ω—É–∂–µ–Ω"""
        pass


# =============================================================================
# 4. –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ô –î–ê–¢–ê–°–ï–¢
# =============================================================================

class EURUSDDataset(Dataset):
    """–î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –º—É–ª—å—Ç–∏—Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö EURUSD"""

    def __init__(self, data_dict, lookback_window=100, num_steps=50, target_timeframe='M5'):
        self.data_dict = data_dict
        self.lookback_window = lookback_window
        self.num_steps = num_steps
        self.target_timeframe = target_timeframe
        self.encoder = FinancialSpikeEncoder(num_time_steps=num_steps)

        self.expected_timeframes = ['M5', 'M15', 'H1', 'H4']

        self._validate_and_preprocess_data()
        self._create_timeline()

    def _validate_and_preprocess_data(self):
        self.processed_data = {}
        self.available_timeframes = []

        print("üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã...")

        for tf_name in self.expected_timeframes:
            if tf_name in self.data_dict and self.data_dict[tf_name] is not None:
                df = self.data_dict[tf_name]

                if len(df) > self.lookback_window:
                    self.available_timeframes.append(tf_name)
                    print(f"   ‚úÖ {tf_name}: {len(df)} –±–∞—Ä–æ–≤")

                    features = self._preprocess_dataframe(df)
                    self.processed_data[tf_name] = features
                else:
                    print(f"   ‚ö†Ô∏è {tf_name}: –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö ({len(df)} –±–∞—Ä–æ–≤)")
            else:
                print(f"   ‚ùå {tf_name}: –¥–∞–Ω–Ω—ã–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç")

        if not self.available_timeframes:
            raise ValueError("‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤ —Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –¥–∞–Ω–Ω—ã—Ö")

        if self.target_timeframe not in self.processed_data:
            if 'M5' in self.processed_data:
                self.target_timeframe = 'M5'
            else:
                self.target_timeframe = self.available_timeframes[0]
            print(f"‚ö†Ô∏è –¶–µ–ª–µ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º –∏–∑–º–µ–Ω–µ–Ω –Ω–∞ {self.target_timeframe}")

        print(f"üéØ –¶–µ–ª–µ–≤–æ–π —Ç–∞–π–º—Ñ—Ä–µ–π–º: {self.target_timeframe}")
        print(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–∞–π–º—Ñ—Ä–µ–π–º—ã: {self.available_timeframes}")

    def _preprocess_dataframe(self, df):
        required_columns = ['open', 'high', 'low', 'close', 'tick_volume']

        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            available_cols = list(df.columns)
            raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–æ–ª–æ–Ω–∫–∏: {missing_columns}. –î–æ—Å—Ç—É–ø–Ω—ã: {available_cols}")

        features = df[required_columns].values

        # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ü–µ–Ω –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        price_columns = ['open', 'high', 'low', 'close']
        price_indices = [required_columns.index(col) for col in price_columns]

        for idx in price_indices:
            features[:, idx] = np.log(features[:, idx])

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—ä–µ–º–∞
        volume_idx = required_columns.index('tick_volume')
        features[:, volume_idx] = np.log1p(features[:, volume_idx])

        return features

    def _create_timeline(self):
        target_data = self.processed_data[self.target_timeframe]

        self.valid_indices = list(range(
            self.lookback_window,
            len(target_data) - 1
        ))

        print(f"üìà –î–æ—Å—Ç—É–ø–Ω–æ samples: {len(self.valid_indices)}")

    def __len__(self):
        return len(self.valid_indices)

    def __getitem__(self, idx):
        real_idx = self.valid_indices[idx]
        multi_tf_data = []

        timeframe_ratios = {
            'M5': 1,
            'M15': 3,
            'H1': 12,
            'H4': 48
        }

        for tf_name in self.available_timeframes:
            data = self.processed_data[tf_name]
            ratio = timeframe_ratios.get(tf_name, 1)

            window_start = max(0, (real_idx - self.lookback_window) // ratio)
            window_end = real_idx // ratio

            if window_end >= len(data):
                window_end = len(data) - 1
                window_start = max(0, window_end - (self.lookback_window // ratio))

            window_data = data[window_start:window_end]

            if len(window_data) < self.lookback_window:
                padding_needed = self.lookback_window - len(window_data)
                padding = np.tile(window_data[0:1], (padding_needed, 1))
                window_data = np.vstack([padding, window_data])

            # –ö–æ–¥–∏—Ä—É–µ–º –≤ —Å–ø–∞–π–∫–∏
            window_data_reshaped = window_data.reshape(1, self.lookback_window, 5)
            spikes = self.encoder.price_change_encoding(window_data_reshaped)

            # spikes shape: (1, 3, lookback_window, num_steps)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫ (3, lookback_window, num_steps)
            spikes = spikes.squeeze(0)

            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –¥–æ–±–∞–≤–ª—è–µ–º –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—ã—Å–æ—Ç—ã (–¥–µ–ª–∞–µ–º lookback_window –∫–∞–∫ height)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º (3, lookback_window, num_steps) -> (3, lookback_window, 1, num_steps)
            spikes = spikes.unsqueeze(2)  # –¥–æ–±–∞–≤–ª—è–µ–º width=1

            multi_tf_data.append(spikes)

        # –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π —Ç–µ–Ω–∑–æ—Ä: (num_timeframes, 3, height, width, num_steps)
        # –≥–¥–µ height = lookback_window, width = 1
        multi_tf_tensor = torch.stack(multi_tf_data)

        # –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
        target_data = self.processed_data[self.target_timeframe]
        future_price = target_data[real_idx + 1, 3]
        current_price = target_data[real_idx, 3]

        price_ratio = np.exp(future_price - current_price)

        threshold = 1.0005 if self.target_timeframe == 'M5' else 1.001

        if price_ratio > threshold:
            target = 2  # UP
        elif price_ratio < (2 - threshold):
            target = 0  # DOWN
        else:
            target = 1  # SIDEWAYS

        return multi_tf_tensor, torch.tensor(target, dtype=torch.long)

def create_mock_eurusd_data():
    """–°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è EURUSD"""
    print("üîÑ –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ EURUSD...")

    base_dates = pd.date_range(start='2024-01-01', end='2025-01-01', freq='5min')[:5000]

    mock_data = {}

    timeframe_configs = [
        ('M5', 1),
        ('M15', 3),
        ('H1', 12),
        ('H4', 48)
    ]

    # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è M5 —Å —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–º –ø–æ–≤–µ–¥–µ–Ω–∏–µ–º EURUSD
    np.random.seed(42)
    base_prices = []
    price = 1.1000  # –ù–∞—á–∞–ª—å–Ω–∞—è —Ü–µ–Ω–∞ EURUSD

    for i in range(len(base_dates)):
        # –ë–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–≤–∏–∂–µ–Ω–∏—è EURUSD
        trend = 0.00001  # –°–ª–∞–±—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥
        volatility = 0.0008  # –í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å EURUSD
        change = np.random.normal(trend, volatility)
        price = max(0.9, min(1.3, price * (1 + change)))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑—É–º–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        base_prices.append(price)

    for tf_name, multiplier in timeframe_configs:
        data = []

        for i in range(0, len(base_prices), multiplier):
            if i >= len(base_prices):
                break

            base_idx = i
            open_price = base_prices[base_idx]

            period_high = max(base_prices[base_idx:min(base_idx + multiplier, len(base_prices))])
            period_low = min(base_prices[base_idx:min(base_idx + multiplier, len(base_prices))])

            close_idx = min(base_idx + multiplier - 1, len(base_prices) - 1)
            close_price = base_prices[close_idx]

            volume = np.random.randint(100 * multiplier, 1000 * multiplier)

            data.append({
                'open': open_price,
                'high': period_high,
                'low': period_low,
                'close': close_price,
                'tick_volume': volume
            })

        df = pd.DataFrame(data)

        if tf_name == 'M5':
            df.index = base_dates[:len(df)]
        else:
            df.index = base_dates[::multiplier][:len(df)]

        mock_data[tf_name] = df
        print(f"‚úÖ {tf_name}: —Å–æ–∑–¥–∞–Ω–æ {len(df)} —Ç–µ—Å—Ç–æ–≤—ã—Ö –±–∞—Ä–æ–≤")

    return mock_data


def verify_onnx_model(onnx_path):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ ONNX –º–æ–¥–µ–ª–∏"""
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        onnx_model = onnx.load(onnx_path)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å
        onnx.checker.check_model(onnx_model)
        print("‚úÖ ONNX –º–æ–¥–µ–ª—å –≤–∞–ª–∏–¥–Ω–∞")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥—ã/–≤—ã—Ö–æ–¥—ã
        print("üìä –ì—Ä–∞—Ñ –º–æ–¥–µ–ª–∏:")
        for input in onnx_model.graph.input:
            print(f"   –í—Ö–æ–¥: {input.name}, —Ñ–æ—Ä–º–∞: {[dim.dim_value for dim in input.type.tensor_type.shape.dim]}")

        for output in onnx_model.graph.output:
            print(f"   –í—ã—Ö–æ–¥: {output.name}, —Ñ–æ—Ä–º–∞: {[dim.dim_value for dim in output.type.tensor_type.shape.dim]}")

        # –¢–µ—Å—Ç–∏—Ä—É–µ–º inference
        session = ort.InferenceSession(onnx_path)
        print("‚úÖ ONNX Runtime —Å–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ ONNX: {e}")
        return False

def export_to_onnx(model, model_path, input_shape, device='cuda'):
    """
    –≠–∫—Å–ø–æ—Ä—Ç –º–æ–¥–µ–ª–∏ –≤ ONNX —Ñ–æ—Ä–º–∞—Ç –Ω–∞ CUDA
    """
    try:
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏ –∏ –Ω–∞ CUDA
        model.eval()
        model = model.to(device)  # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ CUDA

        # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–π –≤—Ö–æ–¥ –Ω–∞ CUDA
        dummy_input = torch.randn(input_shape, device=device)  # –°–æ–∑–¥–∞–µ–º –Ω–∞ CUDA

        # –≠–∫—Å–ø–æ—Ä—Ç –≤ ONNX
        torch.onnx.export(
            model,
            dummy_input,
            model_path,
            export_params=True,
            opset_version=14,
            do_constant_folding=True,
            input_names=['input'],
            output_names=['output'],
            dynamic_axes={
                'input': {0: 'batch_size'},
                'output': {0: 'batch_size'}
            },
            verbose=True
        )

        print(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–∞ –≤: {model_path}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
        file_size = os.path.getsize(model_path) / (1024 * 1024)
        print(f"üì¶ –†–∞–∑–º–µ—Ä ONNX —Ñ–∞–π–ª–∞: {file_size:.2f} MB")

        return True

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–∞ –≤ ONNX: {e}")
        return False


if __name__ == "__main__":
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å CUDA
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üéØ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ! –≠–∫—Å–ø–æ—Ä—Ç –±—É–¥–µ—Ç –Ω–∞ CPU")
        device = 'cpu'

    try:
        # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º—É –≤—Ö–æ–¥–∞
        print("üì• –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ñ–æ—Ä–º—ã...")
        data_dict = create_mock_eurusd_data()
        dataset = EURUSDDataset(
            data_dict=data_dict,
            lookback_window=80,
            num_steps=50,
            target_timeframe='M5'
        )
        sample_input, _ = dataset[0]
        input_shape = (1, sample_input.shape[0], sample_input.shape[1],
                       sample_input.shape[2], sample_input.shape[3], sample_input.shape[4])
        print(f"üìê –§–æ—Ä–º–∞ –≤—Ö–æ–¥–∞: {input_shape}")

        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ —Å –≤–µ—Å–∞–º–∏
        model_path = "saved_models/epoch_8_train_34.17_val_35.02.pth"
        if not os.path.exists(model_path):
            print(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_path}")
            exit()

        # 3. –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
        print("üß† –°–æ–∑–¥–∞–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏...")
        model = MultiTimeframeSpikingResNeXt(
            num_timeframes=len(dataset.available_timeframes),
            num_classes=3,
            num_steps=50
        )

        # 4. –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        print("üì• –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏...")
        state_dict = torch.load(model_path, map_location=device)  # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model.load_state_dict(state_dict)

        # 5. –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –Ω—É–∂–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        model = model.to(device)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏ –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–∞ –Ω–∞ {device}")

        # 6. –ü–µ—Ä–µ–≤–æ–¥–∏–º –º–æ–¥–µ–ª—å –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏
        model.eval()
        print("üîç –ú–æ–¥–µ–ª—å –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –≤ —Ä–µ–∂–∏–º –æ—Ü–µ–Ω–∫–∏")

        # 7. –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤ ONNX
        print("üîÑ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª—å –≤ ONNX...")
        success = export_to_onnx(model, 'eurusd_spiking_resnext_eph8_35.02.onnx', input_shape, device)

        if success:
            print("üéâ ONNX —ç–∫—Å–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º ONNX –º–æ–¥–µ–ª—å
            verify_onnx_model('eurusd_spiking_resnext_eph8_35.02.onnx')
        else:
            print("‚ùå ONNX —ç–∫—Å–ø–æ—Ä—Ç –Ω–µ —É–¥–∞–ª—Å—è")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback

        traceback.print_exc()